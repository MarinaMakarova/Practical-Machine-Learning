abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
#manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
install.packages("manipulate")
library(manipulate)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
next()
nxt()
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
?"manipulate"
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
plot(x, y)
?lm
coef(lm(y ~ x))[2]
data("mtcars")
cars <- lm(mpg ~ weight, mtcars)
View(mtcars)
cars <- lm(mpg ~ wt, mtcars)
summary(cars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean_x <- mean(x)
sd_x <- sd(x)
x_norm <- (x-mean_x)/sd_x
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
num_7 <- lm(y ~ x)
plot(x,y)
abline(num_7, lwd = 2, col = "red")
summary(num_7)
p <- <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
p <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
manipulate(p)
?"manipulate"
mean(p)
a <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(a)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
x_y <- y*x
x2 <- x^2
?sum
sum(x_y)
sum(x_y)/sum(x2)
a <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
sum(w*(a-.3)^2)
sum(w*(a-0.0025)^2)
sum(w*(a-1.077)^2)
sum(w*(a-0.1471)^2)
library(swirl)
swirl()
fit <- lm(child ~ parent, galton)
sqrt(fit$residuals/(n-2))
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
deviance(fit)/(n-2)
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1- sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child~1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant - 1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
lm(Fertility~ . , swiss)
all <- lm(Fertility ~ ., swiss)
summary(all)
summary(lm(Fertility ~ Agriculture, swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- sum(swiss$Examination, swiss$Catholic)
ec <- swiss$Examination+swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
efit - all
efit - all
coef(efit) - coef(all)
all$coefficients-efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
resid(fit)
e <- resid (fit)
sd <- sqrt((e - mean(e))^2/9)
sd
sd <- sqrt(sum((e - mean(e))^2)/9)
sd
data("mtcars")
summary(fit)$sigma
head(mtcars)
fit2 <- lm(mpg ~ wt, mtcars)
summary(fit2)
-5.3445 - qt(0.975, fit2$df)*fit2$sigma
fit2$df.residual
-5.3445 - qt(0.975, fit2$df.residual)*fit2$sigma
-5.3445 - qt(0.975, fit2$df.residual)*summary(fit2)$sigma
predict(fit2, newdata=data.frame(wt=mean(mtcars$wt)),interval="confidence")
?mtcars
predict(fit2, newdata=data.frame(wt = 3),interval="confidence")
predict(fit2, newdata=data.frame(wt = c(3)),interval="confidence")
fit <- lm(mpg ~ wt, data=mtcars)
(summary(fit)$coeff)
newdata <- data.frame(wt=mean(mtcars$wt))
predict(fit, newdata, interval=("confidence"))
newdata <- data.frame(wt=3000/1000)
predict(fit, newdata, interval=("prediction"))
predict(fit, newdata, interval=("confidence"))
fit2 <- lm(mpg ~ I(wt*2), data = mtcars)
fit2 <- lm(mpg ~ I(wt/2), data = mtcars)
coef <- summary(fit)$coeff
coef[2,1] + c(-1, 1) * qt(.975, df=fit$df) * coef[2,2]
coef[2,1] + c(-1, 1) * qt(.975, df=fit2$df) * coef[2,2]
coef[2,1] + c(-1, 1) * qt(.975, 30) * coef[2,2]
coef[2,1] + c(-1, 1) * qt(.975, 31) * coef[2,2]
fit2<-lm(mpg~I(wt/2), data=mtcars)
sumCoef <- summary(fit2)$coefficients
fit2<-lm(mpg~I(wt/2), data=mtcars)
sumCoef <- summary(fit2)$coefficients
sumCoef[2,1] + c(-1,1) * qt(.975, df = fit2$df) * sumCoef[2,2]
fit<-lm(mpg~wt, data=mtcars)
e1<-resid(fit)
fit2<-lm(mpg~1, data=mtcars)
e2<-resid(fit2)
sum(e1^2)/sum(e2^2)
require(datasets)
data("swiss")
?swiss
library(ggplot2)
install.packages("GGally")
install.packages("GGally")
library("GGally")
require("GGally")
g <- ggpairs(swiss, lower = list(continuous = "smooth"), params = c(method = "loess"))
library(ggplot2)
library(GGally)
g <- ggpairs(swiss, lower = list(continuous = "smooth"), params = c(method = "loess"))
require(GGally)
install.packages("GGally")
library("GGally")
require(GGally)
g <- ggpairs(swiss, lower = list(continuous = "smooth"), params = c(method = "loess"))
summary(lm(Fertility ~., data = swiss))$coefficients
summary(lm(Fertility ~ Agriculture, data = swiss))$coefficients
n <- 100; x2 <- 1 : n; x1 <- .01 * x2 + runif(n, -.1, .1); y = -x1 + x2 + rnorm(n, sd = .01)
summary(lm(y ~ x1))$coef
summary(lm(y ~ x1 + x2))$coef
z <- swiss$Agriculture + swiss$Education
lm(Fertility ~ . + z, data = swiss)
require(datasets);data(InsectSprays)
require(stats); require(graphics)
g = ggplot(data = InsectSprays, eas(y = count, x = spray, fill = spray))
g = ggplot(data = InsectSprays, aes(y = count, x = spray, fill = spray))
g = g + xlab("Type of spray") + ylab("Insect count")
g
g = g + geom_violin(colour = "black", size =2)
g
summary(lm(count ~ spray, data = InsectSprays))$coef
summary(lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F'))
, data = InsectSprays))$coef
lm(count ~
I(1 * (spray == 'B')) + I(1 * (spray == 'C')) +
I(1 * (spray == 'D')) + I(1 * (spray == 'E')) +
I(1 * (spray == 'F')) + I(1 * (spray == 'A')), data = InsectSprays)
summary(lm(count ~ spray - 1, data = InsectSprays))$coef
p <- 1
n <- 100; x2 <- runif(n); x1 <- p * runif(n) - (1 - p) * x2
beta0 <- 0; beta1 <- 1; tau <- 4 ; sigma <- .01
y <- beta0 + x1 * beta1 + tau * x2 + rnorm(n, sd = sigma)
plot(x1, y, type = "n", frame = FALSE)
abline(lm(y ~ x1), lwd = 2)
co.pal <- heat.colors(n)
points(x1, y, pch = 21, col = "black", bg = co.pal[round((n - 1) * x2 + 1)], cex = 2)
n <- 100; nosim <- 1000
x1 <- rnorm(n); x2 <- rnorm(n); x3 <- rnorm(n)
betas <- sapply(1 : nosim, function(i){
y <- x1 + rnorm(n, sd = .3)
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
x1 <- rnorm(n); x2 <- x1/sqrt(2) + rnorm(n) /sqrt(2)
x3 <- x1 * 0.95 + rnorm(n) * sqrt(1 - 0.95^2)
betas <- sapply(1 : nosim, function(i){
y <- x1 + rnorm(n, sd = .3)
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
})
round(apply(betas, 1, sd), 5)
library(swirl)
swirl()
6
dim(InsectSprays)
head(InsectSprays, 15)
sF
summary(InsectSprays[,2])
sapply(InsectSprays, class)
fit <- lm(count~ spray, data = InsectSprays)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count ~ spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2] - fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmf <- lm(Numeric [hunger$Sex=="Female"] ~ Year[hunger$Sex=="Female"], hunger)
lmF <- lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth <- lm(Numeric ~ Year+Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, hunger)
summary(lmInter)
fit <- lm (y~x, out2)
plot(fit, which=1)
fitno <- lm (y~x, out2[-1, ])
plot(fitno, which=1)
coef(fitno) - coef(fit)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(sum(resid(fit)^2)/df(resid(fit)))
sigma <- sqrt(sum(resid(fit)^2)/df.residual(fit))
rstd <- resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(sum(resid(fitno)^2)/df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno, out2) - predict(fit, out2)
sum(dy^2)/2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
data("mtcars")
data("mtcars")
names(mtcars)
m1 <- lm(mpg ~ cyl + wt, mtcars)
summary(m1)$coef
m1 <- lm(mpg ~ cyl + wt, mtcars[mtcars$cyl == 8])
m1 <- lm(mpg[mtcars$cyl == 8] ~ cyl[mtcars$cyl == 8] + wt[mtcars$cyl == 8], mtcars)
m2 <- lm(mpg[mtcars$cyl == 4] ~ cyl[mtcars$cyl == 4] + wt[mtcars$cyl == 4], mtcars)
summary(m1)$coef
summary(m1)$coef[1] - summary(m2)$coef[1]
summary(m1)$coef[2]
summary(m1)$coef[2] - summary(m2)$coef[2]
mtcars$cyl = as.factor(mtcars$cyl)
fit = lm(mpg~factor(cyl)+wt,data=mtcars)
summary(fit)$coefficients[3]
fit2 = lm(mpg~factor(cyl),data=mtcars)
summary(fit2)$coefficients[3]
fit2 = lm(mpg~factor(cyl)*wt,data=mtcars)
anova(fit2,fit4, test="Chisq")
anova(fit,fit2, test="Chisq")
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit3 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit3)$coef
?mtcars
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit5 <- lm(y~x)
max(hatvalues(fit5))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit6 <- lm(y~x)
dfbeta(max(hatvalues(fit6)))
dfbetas(fit6)[which(hatvalues(fit6)==max(hatvalues(fit6))),2]
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
?AlzheimerDisease
?createDataPartition
install.packages(Caret)
install.packages(caret)
install.packages("caret")
library("caret")
?createDataPartition
View(predictors)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("Hmisc")
library("Hmisc")
?cut2
groups <- cut2(mixtures$CompressiveStrength, g = 10)
View(mixtures)
names <- colnames(concrete)
names <- names[-length(names)]
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
index <- seq_along(1:nrow(training))
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() +
theme_bw()
cutCS <- cut2(training$CompressiveStrength, g = 5)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") +
theme_bw()
featurePlot(x = training[, names], y = cutCS, plot = "box")
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(predictors)
?grep
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
?preProcess
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
library("caret")
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with the caret package
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
A2 <- C2$overall[1]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(4,4,4,4))
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(4,4,3,4))
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(4,4,7,4))
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(4,4,1,4))
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(4,4,3,4))
plot(modFit$finalModel, uniform=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(1,1,1,1))
plot(modFit$finalModel, uniform=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(1,2,1,1))
plot(modFit$finalModel, uniform=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(1,3,1,1))
plot(modFit$finalModel, uniform=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
par(mar = c(1,3,0,1))
plot(modFit$finalModel, uniform=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
View(olive)
View(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(SAheart)
View(SAheart)
?SAheart
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = SAheart, method="glm", family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA, predict(model, newdata = trainSA)
)
missClass(trainSA$chd, predict(model, newdata = trainSA)
)
missClass(testSA$chd, predict(model, newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
class(vowel.test$y)
set.seed(33833)
?varImp
modFit <- train(y ~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modFit)
setwd("~/Desktop/Data science/Practical Machine Learning/final project")
Sys.info()
version
sessionInfo()
library(caret)
sessionInfo()
URLtrain <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(URLtrain)
testing <- read.csv(URLtest)
